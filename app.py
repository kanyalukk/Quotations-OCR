
# app.py (boosted extraction accuracy)
import os, re, json, shutil
from typing import Dict, List, Tuple, Optional
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image
import cv2
import dateparser

# --- Optional OCR engines ---
EASYOCR_AVAILABLE = True
try:
    import easyocr  # requires torch
except Exception:
    EASYOCR_AVAILABLE = False

try:
    import pytesseract
except Exception:
    pytesseract = None

# -------------------- Utilities --------------------

THAI_DIGITS = str.maketrans("‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô", "0123456789")
TH_MONTHS = {
    "‡∏°.‡∏Ñ.":"‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°","‡∏Å.‡∏û.":"‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå","‡∏°‡∏µ.‡∏Ñ.":"‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°","‡πÄ‡∏°.‡∏¢.":"‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô",
    "‡∏û.‡∏Ñ.":"‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°","‡∏°‡∏¥.‡∏¢.":"‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô","‡∏Å.‡∏Ñ.":"‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°","‡∏™.‡∏Ñ.":"‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°",
    "‡∏Å.‡∏¢.":"‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô","‡∏ï.‡∏Ñ.":"‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°","‡∏û.‡∏¢.":"‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô","‡∏ò.‡∏Ñ.":"‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"
}

def to_english_digits(s: str) -> str:
    return s.translate(THAI_DIGITS) if isinstance(s, str) else s

def fix_numberlike_ocr(s: str) -> str:
    if not isinstance(s, str): return s
    s = re.sub(r'(?<=\d)[oO](?=[\d,\.])', '0', s)
    s = re.sub(r'(?<=[,\.\s])[oO](?=\d)', '0', s)
    s = re.sub(r'(?<=\d)[lI](?=[\d,\.])', '1', s)
    s = re.sub(r'(?<=\d)B(?=[\d,\.])', '8', s)
    return s

def normalize_number(s: str) -> Optional[float]:
    if not s: return None
    s = to_english_digits(s)
    s = fix_numberlike_ocr(s)
    s = s.replace(" ", "").replace(",", "").replace("‡∏ø", "").replace("‡∏ö‡∏≤‡∏ó", "").replace("‡∏ø.", "")
    s = s.replace("%","")
    m = re.findall(r"-?\d+(?:\.\d+)?", s)
    return float(m[0]) if m else None

def sanitize_text(text: str) -> str:
    if not text: return ""
    text = to_english_digits(text)
    for short, full in TH_MONTHS.items():
        text = re.sub(short, full, text)
    text = re.sub(r"[ \t]+", " ", text)
    text = text.replace("‚Äî", "-").replace("‚Äì", "-").replace("Ôºö", ":")
    return text

def parse_date_candidates(text: str) -> Optional[str]:
    text = sanitize_text(text)
    candidates = set()
    for m in re.finditer(r"(‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|date)[:\s\-]*([^\n]{0,30})", text, flags=re.IGNORECASE):
        candidates.add(m.group(0))
    candidates.update(re.findall(r"\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b", text))
    candidates.update(re.findall(r"\b\d{4}[/-]\d{1,2}[/-]\d{1,2}\b", text))
    th_month_regex = r"(‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°)"
    candidates.update(re.findall(rf"\b\d{{1,2}}\s*{th_month_regex}\s*\d{{2,4}}\b", text))
    parsed = []
    for c in list(candidates)[:20]:
        dt = dateparser.parse(c, languages=["th","en"], settings={"PREFER_DATES_FROM":"past","DATE_ORDER":"DMY"})
        if dt:
            if dt.year > 2400: dt = dt.replace(year=dt.year-543)
            parsed.append(dt.date())
    if not parsed: return None
    return sorted(parsed, key=lambda x: x.toordinal())[-1].isoformat()

def deskew(binary_img: np.ndarray) -> Tuple[np.ndarray, float]:
    coords = np.column_stack(np.where(binary_img > 0))
    if coords.size == 0: return binary_img, 0.0
    angle = cv2.minAreaRect(coords)[-1]
    angle = -(90 + angle) if angle < -45 else -angle
    (h, w) = binary_img.shape[:2]
    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)
    rotated = cv2.warpAffine(binary_img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated, angle

def preprocess(img_bgr: np.ndarray) -> Dict[str, np.ndarray]:
    out = {}
    out["original"] = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    out["grayscale"] = gray
    blur = cv2.medianBlur(gray, 3)
    out["denoise(median3)"] = blur
    th = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 9)
    out["adaptive_threshold"] = th
    de, ang = deskew(th)
    out["deskewed"] = de
    up = cv2.resize(de, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
    out["upscale(1.5x)"] = up
    kernel = np.ones((2, 2), np.uint8)
    opened = cv2.morphologyEx(up, cv2.MORPH_OPEN, kernel, iterations=1)
    out["morph_open"] = opened
    return out

def ensure_tesseract(user_path: Optional[str]) -> Tuple[bool, Optional[str], Optional[str]]:
    if pytesseract is None:
        return (False, None, "pytesseract not installed")
    candidates = []
    if user_path: candidates.append(user_path)
    candidates += [
        "/usr/bin/tesseract","/usr/local/bin/tesseract","/opt/homebrew/bin/tesseract",
        r"C:\Program Files\Tesseract-OCR\tesseract.exe", r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"
    ]
    for c in [p for p in candidates if p]:
        if os.path.exists(c):
            try:
                pytesseract.pytesseract.tesseract_cmd = c
                _ = pytesseract.get_tesseract_version()
                return True, c, None
            except Exception as e:
                last = str(e)
    exe = shutil.which("tesseract")
    if exe:
        try:
            pytesseract.pytesseract.tesseract_cmd = exe
            _ = pytesseract.get_tesseract_version()
            return True, exe, None
        except Exception as e:
            return False, exe, f"Found at {exe} but error: {e}"
    return False, None, "tesseract not found"

def ocr_easyocr(img_rgb: np.ndarray) -> str:
    if not EASYOCR_AVAILABLE: return ""
    reader = easyocr.Reader(["th", "en"], gpu=False)
    res = reader.readtext(img_rgb, detail=0, paragraph=True)
    return "\n".join(res)

def ocr_tesseract(img) -> str:
    config = "--oem 3 --psm 6 -l tha+eng"
    return pytesseract.image_to_string(img, config=config)

def normalize_qt_code(raw: str) -> str:
    if not raw: return raw
    s = raw.strip()
    table = str.maketrans({"$": "S", "¬ß": "S"})
    s = s.translate(table)
    s = re.sub(r"^[Kk]5", "KS", s)
    s = re.sub(r"^5", "S", s)
    s = fix_numberlike_ocr(s)
    s = s.replace(" ", "")
    return s.upper()

def line_numbers_preferring_big(s: str) -> List[float]:
    s_no_pct = re.sub(r"\d+(\.\d+)?\s*%", "", s)
    s_no_pct = fix_numberlike_ocr(s_no_pct)
    nums = re.findall(r"-?\d[\d,]*\.?\d*", s_no_pct)
    vals = []
    for n in nums:
        v = normalize_number(n)
        if v is None: 
            continue
        if v >= 100 or ("," in n) or ("." in n):
            vals.append(v)
    if not vals:
        for n in nums:
            v = normalize_number(n)
            if v is not None:
                vals.append(v)
    return vals

def find_amount_near(text: str, keys: List[str]) -> Optional[float]:
    s = sanitize_text(text)
    lines = [l.strip() for l in s.splitlines() if l.strip()]
    low = [k.lower() for k in keys]
    for i, l in enumerate(lines):
        ll = l.lower()
        if any(k in ll for k in low):
            cand_vals = line_numbers_preferring_big(l)
            if i + 1 < len(lines):
                cand_vals += line_numbers_preferring_big(lines[i+1])
            if cand_vals:
                return max(cand_vals)
    return None

def extract_vendor(text: str) -> Optional[str]:
    t = sanitize_text(text)
    lines = [l.strip() for l in t.splitlines() if l.strip()]
    company_keywords = [
        r"(‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó.+‡∏à‡∏≥‡∏Å‡∏±‡∏î|‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó.+‡∏à‡∏≥‡∏Å‡∏±‡∏î\(‡∏°‡∏´‡∏≤‡∏ä‡∏ô\)|‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏≥‡∏Å‡∏±‡∏î|‡∏´‡∏à‡∏Å\.)",
        r"(co\.,?\s*ltd\.?|company\s*limited|limited\s*company)",
        r"(vendor|supplier|‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢|‡∏ú‡∏π‡πâ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢)[:\s]*([^\n]+)"
    ]
    for l in lines[:30]:
        for pat in company_keywords:
            m = re.search(pat, l, flags=re.IGNORECASE)
            if m:
                cand = m.group(m.lastindex) if (m.lastindex and m.group(m.lastindex)) else l
                cand = re.sub(r"^(vendor|supplier|‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢|‡∏ú‡∏π‡πâ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢)[:\s\-]*", "", cand, flags=re.IGNORECASE)
                cand = re.sub(r"\s{2,}", " ", cand)
                cand = re.sub(r"(‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà|address)[:\s].*$", "", cand, flags=re.IGNORECASE)
                return cand.strip()
    for l in lines[:10]:
        if re.search(r"(‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó|‡∏´‡∏à‡∏Å\.|co\.,?\s*ltd\.?)", l, flags=re.IGNORECASE):
            return l
    return None

def extract_qt_no(text: str) -> Optional[str]:
    t = sanitize_text(text)
    m = re.search(r"(quotation\s*no\.?|quotation\s*#|qt\s*no\.?|‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÉ‡∏ö‡πÄ‡∏™‡∏ô‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤|‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà[:\s]|ref\s*no\.?)\s*[:#]?\s*([A-Za-z0-9\$¬ß\/\-\._]{3,})", t, flags=re.IGNORECASE)
    if m:
        return normalize_qt_code(m.group(2))
    m = re.search(r"\b[A-Z\$¬ß]{1,4}[-/_.]?\d{2,4}[-/_.]?\d{1,6}\b", t, flags=re.IGNORECASE)
    if m:
        return normalize_qt_code(m.group(0))
    return None

def extract_description(text: str) -> Optional[str]:
    t = sanitize_text(text)
    if "product description" in t.lower():
        after = t.lower().split("product description", 1)[1]
        after = re.split(r"(payment\s*term|terms\s*&?\s*conditions|total|vat|grand\s*total)", after, flags=re.IGNORECASE)[0]
        after = re.sub(r"\b(qty\.?|price per.*|total price.*)\b", "", after, flags=re.IGNORECASE)
        line = [ln.strip() for ln in after.splitlines() if len(ln.strip()) >= 10]
        if line:
            return line[0][:180]
    m = re.search(r"(description|‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î|‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)\s*[:\-]?\s*(.+)", t, flags=re.IGNORECASE|re.DOTALL)
    if m:
        tail = m.group(2).strip()
        tail = re.split(r"(subtotal|‡∏£‡∏ß‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ|vat|‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°|grand\s*total|‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏ó‡∏ò‡∏¥)", tail, flags=re.IGNORECASE)[0]
        return tail.strip().splitlines()[0][:180]
    lines = [l.strip() for l in t.splitlines() if l.strip()]
    body = []
    for l in lines:
        if len(l) > 20 and not re.search(r"(tel|fax|email|‡πÄ‡∏•‡∏Ç‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏ú‡∏π‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏†‡∏≤‡∏©‡∏µ|tax\s*id|address|‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà)", l, flags=re.IGNORECASE):
            body.append(l)
        if len(body) >= 2: break
    return " | ".join(body)[:180] if body else None

def extract_fields(full_text: str) -> Dict[str, Optional[str]]:
    txt = sanitize_text(full_text or "")
    vendor = extract_vendor(txt)
    qt_no  = extract_qt_no(txt)
    date_iso = parse_date_candidates(txt)

    subtotal = find_amount_near(txt, ["subtotal", "‡∏£‡∏ß‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ", "‡∏¢‡∏≠‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ", "total"])
    grand    = find_amount_near(txt, ["grand total", "‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏ó‡∏ò‡∏¥", "‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏¥‡πâ‡∏ô", "‡∏¢‡∏≠‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏∏‡∏ó‡∏ò‡∏¥"])
    vat      = find_amount_near(txt, ["vat", "‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°"])

    if vat is not None and vat < 50 and re.search(r"vat\s*7\s*%|‡∏†‡∏≤‡∏©‡∏µ\s*7\s*%", txt, flags=re.IGNORECASE):
        if grand is not None and subtotal is not None:
            vat = round(grand - subtotal, 2)
        elif subtotal is not None:
            vat = round(subtotal * 0.07, 2)
        elif grand is not None:
            vat = None

    if grand is not None and subtotal is not None:
        vat = round(grand - subtotal, 2)
    if vat is not None and grand is not None and subtotal is None:
        subtotal = round(grand - vat, 2)
    if vat is not None and subtotal is not None and grand is None:
        grand = round(subtotal + vat, 2)

    desc = extract_description(txt)

    return {
        "Vendor/Supplier": vendor,
        "Quotation No.": qt_no,
        "Date": date_iso,
        "Description": desc,
        "Subtotal": subtotal,
        "VAT": vat,
        "Grand Total": grand,
        "Raw Text": txt,
    }

def export_to_google_sheets(df: pd.DataFrame, sheet_url: str, service_json: dict, worksheet_name: str = "OCR_QT"):
    try:
        import gspread
        gc = gspread.service_account_from_dict(service_json)
        sh = gc.open_by_url(sheet_url)
        try:
            ws = sh.worksheet(worksheet_name)
        except Exception:
            ws = sh.add_worksheet(title=worksheet_name, rows="1000", cols="26")
        if not ws.get_all_values():
            ws.append_row(list(df.columns))
        for _, row in df.iterrows():
            ws.append_row([str(x) if x is not None else "" for x in row.tolist()])
        return True, "Exported to Google Sheets successfully."
    except Exception as e:
        return False, f"Export failed: {e}"

st.set_page_config(page_title="OCR ‡πÉ‡∏ö‡πÄ‡∏™‡∏ô‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ö‡∏¥‡∏• ‚Üí ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏£‡∏≤‡∏á", layout="wide")
st.title("üßæ OCR ‡πÉ‡∏ö‡πÄ‡∏™‡∏ô‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ö‡∏¥‡∏• ‚ûú ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á")
st.caption("Pre-process ‚ûú OCR (EasyOCR/Tesseract) ‚ûú Regex/NER ‚ûú Export Google Sheets")

with st.sidebar:
    st.header("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    engine = st.selectbox("OCR Engine", ["Hybrid (EasyOCR ‚ûú fallback Tesseract)","Tesseract only","EasyOCR only"], index=0)
    user_tess_path = st.text_input("Tesseract path (‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)", value="")
    show_steps = st.checkbox("‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û Pre-processing ‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô", value=True)
    worksheet_name = st.text_input("Worksheet name (Google Sheets)", value="OCR_QT")
    st.markdown("---")
    st.subheader("üîó ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å Google ‡∏ä‡∏µ‡∏ó (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)")
    sheet_url = st.text_input("‡∏ß‡∏≤‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå Google ‡∏ä‡∏µ‡∏ó ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏î‡πâ", value="")
    service_json_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Service Account JSON", type=["json"], accept_multiple_files=False)

TESS_OK, TESS_PATH, TESS_MSG = ensure_tesseract(user_tess_path.strip() or None)
st.sidebar.markdown("**Tesseract status:** " + ("‚úÖ " + str(TESS_PATH) if TESS_OK else "‚ùå " + str(TESS_MSG)))

st.subheader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡πÉ‡∏ö‡πÄ‡∏™‡∏ô‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ö‡∏¥‡∏• (JPG/PNG)")
uploads = st.file_uploader("Drag & drop ‡∏´‡∏£‡∏∑‡∏≠ Browse files", type=["jpg","jpeg","png"], accept_multiple_files=True)

rows = []
if uploads:
    for up in uploads:
        st.markdown("---")
        c1, c2 = st.columns([1,1])
        with c1:
            st.write(f"**‡πÑ‡∏ü‡∏•‡πå:** {up.name}")
            image = Image.open(up).convert("RGB")
            img_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            steps = preprocess(img_bgr)
            if show_steps:
                tabs = st.tabs(list(steps.keys()))
                for tab, key in zip(tabs, steps.keys()):
                    with tab:
                        st.image(steps[key], caption=key, use_container_width=True, clamp=len(steps[key].shape)==2)
        with c2:
            st.write("**OCR Output (Raw Text)**")
            text_easy = ""
            text_tess = ""
            if engine in ["Hybrid (EasyOCR ‚ûú fallback Tesseract)","EasyOCR only"] and EASYOCR_AVAILABLE:
                try:
                    text_easy = ocr_easyocr(steps["original"])
                except Exception as e:
                    st.warning(f"EasyOCR error: {e}")
            if engine in ["Hybrid (EasyOCR ‚ûú fallback Tesseract)","Tesseract only"] and TESS_OK:
                try:
                    text_tess = ocr_tesseract(steps["morph_open"])
                except Exception as e:
                    st.warning(f"Tesseract error: {e}")
            elif engine in ["Hybrid (EasyOCR ‚ûú fallback Tesseract)","Tesseract only"] and not TESS_OK:
                st.info("Tesseract not found ‚Äî ‡πÉ‡∏ä‡πâ EasyOCR ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏ path ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏ã‡πâ‡∏≤‡∏¢")

            raw = ""
            if engine == "EasyOCR only":
                raw = text_easy
            elif engine == "Tesseract only":
                raw = text_tess
            else:
                raw = text_easy if len(text_easy) >= len(text_tess) else text_tess
                if not raw and text_easy:
                    raw = text_easy
            st.text_area("Raw Text", value=raw, height=260)

            fields = extract_fields(raw or "")
            row = {
                "file": up.name,
                "Vendor / Supplier": fields["Vendor/Supplier"],
                "Quotation No.": fields["Quotation No."],
                "Date": fields["Date"],
                "Description": fields["Description"],
                "Subtotal": fields["Subtotal"],
                "VAT": fields["VAT"],
                "Grand Total": fields["Grand Total"],
            }
            rows.append(row)
            st.write("**‡∏™‡∏£‡∏∏‡∏õ‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î‡πÑ‡∏î‡πâ**")
            st.dataframe(pd.DataFrame([row]))

if rows:
    st.markdown("## ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°")
    df = pd.DataFrame(rows, columns=["file","Vendor / Supplier","Quotation No.","Date","Description","Subtotal","VAT","Grand Total"])
    st.dataframe(df, use_container_width=True)
    st.download_button("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", data=df.to_csv(index=False).encode("utf-8-sig"), file_name="ocr_quotation_results.csv", mime="text/csv")
    if sheet_url and service_json_file is not None:
        try:
            service_dict = json.load(service_json_file)
        except Exception as e:
            st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON: {e}")
            service_dict = None
        if service_dict is not None and st.button("üöÄ ‡πÇ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏∂‡πâ‡∏ô Google ‡∏ä‡∏µ‡∏ó"):
            ok, msg = export_to_google_sheets(df, sheet_url, service_dict, worksheet_name=worksheet_name)
            (st.success if ok else st.error)(msg)

st.markdown("---")
with st.expander("‚ÑπÔ∏è Notes on accuracy"):
    st.markdown("""
- ‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏Å‡∏•‡πâ‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î
- ‡πÅ‡∏Å‡πâ `10o,ooo.00` ‚ûú `100000.00`, `B` ‚ûú `8`, `I/l` ‚ûú `1`
- Quotation No.: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö `k$2209191` ‚ûú `KS2209191`
- Description: ‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏ï‡πâ **Product Description** ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ fallback ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏°
""")
